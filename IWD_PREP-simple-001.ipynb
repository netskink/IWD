{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28fc016-b123-43b6-8841-00fddb59a0aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic Image classifcation using the FashionNist Sample Dataset\n",
    "\n",
    "This is a simplified version of the example provided in the GluonCV AWS class on Coursera.\n",
    "\n",
    "The original exercise normalized the data, did a two layer DNN and then enhanced the example using convolution and pooling layers.\n",
    "\n",
    "This simplified version is a step wise process of doing the exercise with just the DNN, normalizing the input data is done in \n",
    "a second notebook.  Likewise using convolution and pooling is done in a third notebook.\n",
    "\n",
    "The dataset api is [here](https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/data/vision/datasets/index.html)\n",
    "The source for the mxnet dataset api is [here](https://mxnet.apache.org/versions/1.5.0/_modules/mxnet/gluon/data/vision/datasets.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "747a5ca9-7574-4f83-81eb-9953b3ce751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mxnet) (1.22.3)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mxnet) (2.27.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.20.0->mxnet) (3.3)\n",
      "Requirement already satisfied: scikit-learn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (1.22.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.31.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.63.1)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install mxnet\n",
    "pip install scikit-learn\n",
    "pip install matplotlib\n",
    "# progress bar\n",
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71504f58-e47b-4495-b2a8-d61d529ebbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libs\n",
    "import mxnet as mx\n",
    "# mxnet NDarray shortcut\n",
    "from mxnet import nd\n",
    "# import gluon\n",
    "from mxnet import gluon, init, nd, autograd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet.gluon.data.vision import FashionMNIST\n",
    "from mxnet.gluon.loss import SoftmaxCrossEntropyLoss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# for numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "# file io\n",
    "import os\n",
    "import math # for pi\n",
    "\n",
    "# script parameters\n",
    "import sys\n",
    "\n",
    "# for path operations\n",
    "from pathlib import Path\n",
    "\n",
    "# for progress bars\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18a8fe36-7843-41a1-8a48-00468a17378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/minc-2500'\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'val')\n",
    "test_path = os.path.join(path, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e3073-7d10-482c-b0bb-f2bd241ed94b",
   "metadata": {},
   "source": [
    "# Reference for mxnet approach to this problem\n",
    "Using this code as a sample reference\n",
    "https://github.com/rtp-aws/devpost_aws_disaster_response/blob/main/python/coursera_gluonCV_class/notebook/module_4_lab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99beac67-1ac7-4649-b9db-1a00541caf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('DATA_DIR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "454908f5-823c-4394-829a-c2715e744303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG M4_DATA = Path(os.getenv('DATA_DIR', '../../data'), 'module_4')\n",
    "M4_DATA = Path(os.getenv('DATA_DIR', '../data'), 'module_4')\n",
    "M4_IMAGES = Path(M4_DATA, 'images')\n",
    "M4_MODELS = Path(M4_DATA, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a17c342-da43-4f01-9474-6dfe31a3f880",
   "metadata": {},
   "source": [
    "# Data (and NDArray Operations)\n",
    "\n",
    "We'll use the in-built dataset called FashionMNIST which is a variant of the commonly used MNIST dataset. It consists of 60,000 training images and 10,000 test images, and each image is a 28px by 28px greyscale image. We'll start by creating the dataset and visualize an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df99f3b5-ce18-425f-88e4-c3b5d759df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FashionMNIST(train=False, root=M4_IMAGES).transform_first(transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "425a5cf8-a5fa-43f7-a45a-d94a7d5b40f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the class names as strings\n",
    "#                0             1          2           3        4       5         6        7          8      9       \n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6707bcf4-69a6-48ee-a5f4-707a6beabecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image label encoding is  4\n",
      "the sample label human readable is  Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARlklEQVR4nO3dW4zd1XXH8d/C4Nv4Io8HDzbYOATbwkKqUxlcqVblCpoQXnBeUHgoVLLqPCQokfJQBA/hpQKVJjRIVcRQUAxKHUVKEDygKgQZaHiIMIiLMS24XG1sD5EZe8b3y+rD/EEDzFlrOP9zG+/vRxrNzFnzP2f7b/98zpz133ubuwvA+e+Cbg8AQGcQdqAQhB0oBGEHCkHYgUJc2MkHMzPe+m/CjBkzwvqSJUsa1vr6+sJjL7ww/idwwQXx88G5c+fC+tmzZxvWRkdHw2MPHjwY1ukkTc7dbbLba4XdzG6Q9HNJMyT9h7vfW+f+piuzSc/tZ+r+o1ywYEFY37JlS8Pahg0bwmMHBwfD+pw5c8L68ePHw/rIyEjD2nPPPRcee99994X1U6dOhXV8XtMv481shqR/l/RtSWsl3WJma1s1MACtVed39msl7XH3d9z9lKRfS7qpNcMC0Gp1wn6ppA8nfL+3uu1zzGyrme00s501HgtATW1/g87dhyQNSbxBB3RTnWf2fZKWT/j+suo2AD2oTthflLTKzL5mZjMlfVfSk60ZFoBWszptITO7UdK/abz19oi7/3Py8+fly/iZM2eG9axFdOutt4b1e+65J6yfOHGiYW1sbCw8NuuTZ336WbNmhfUjR440rM2dOzc8NuvxZ+dlaGioYe2iiy4Kjz19+nRY72Vt6bO7+1OSnqpzHwA6g8tlgUIQdqAQhB0oBGEHCkHYgUIQdqAQtfrsX/nBerjPXnfedh3ZVM9ovroknTlzpmEt6ycfPnw4rGfz3Y8dOxbWBwYGGtZOnjwZHtvf3x/W33rrrbB+/fXXN6y1e1pyNzXqs/PMDhSCsAOFIOxAIQg7UAjCDhSCsAOF6OhS0r0sa61FrZq6bZpDhw6F9WwF2Kj1tmzZsvDYlStXhvWsPTZv3ryw/sEHHzSsZec8W7n2/vvvD+uR6dxaaxbP7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIIprpU6Ux4vueSS8Ni77rorrK9ZsyasX3XVVWE9Wi466sFL0uLFi8N61mePlrHO6tkU1uyxP/zww7Ae/b08+OCD4bEPPPBAWO9lTHEFCkfYgUIQdqAQhB0oBGEHCkHYgUIQdqAQ9NmnaMWKFQ1rO3bsCI+Nti2WpIMHD4b11atXh/Wol55tqXz27NmwPmfOnLA+MjIS1qO5+Nk1AAcOHAjr+/fvD+vR9QnZdRXXXHNNWM/G1k1t2bLZzN6TNCrprKQz7r6+zv0BaJ9WrFTzt+7+5xbcD4A24nd2oBB1w+6Sfm9mL5nZ1sl+wMy2mtlOM9tZ87EA1FD3ZfxGd99nZkskPW1m/+Puz0/8AXcfkjQkTe836IDprtYzu7vvqz4PS3pc0rWtGBSA1ms67GbWZ2bzP/1a0jcl7WrVwAC0Vp2X8YOSHq/6lRdK+k93/6+WjKoHbd68uWEt29Y4WjtdkubPn9/MkD4zOjrasJb10WfMmBHWszXt+/r6wvrw8HBYj2R9+L1794b1aM38bCvr22+/PaxnaxT0oqbD7u7vSPqLFo4FQBvRegMKQdiBQhB2oBCEHSgEYQcKwZbNU7R27dqGtWzJ49OnT4f1o0ePhvVsOuYFFzT+P3vu3LnhsXv27AnrWWsuaztG5yZrf2VtvWzqcDT27O/kW9/6Vlifjq03ntmBQhB2oBCEHSgEYQcKQdiBQhB2oBCEHSgEffYpirY2znrR2VLRK1euDOvZNNVz5841rGW96OXLl4f17BqCbGx1js2muGZTg6Nl0rPHPnbsWFifjnhmBwpB2IFCEHagEIQdKARhBwpB2IFCEHagEPTZp2jJkiUNa1mfPdv2OOqTS9KpU6fCejQ3O9uSO5oLL0nHjx8P67Nnzw7rUa985syZ4bF11wGI5vKfOHEiPDa6rkKSNm3aFNafffbZsN4NPLMDhSDsQCEIO1AIwg4UgrADhSDsQCEIO1AI+uyVbP3zefPmNaxlvejLLrssrGf95DqyP1edNemncnw0bzy7viBbV37FihVhPerxZ4+drbd/3XXXhfVp2Wc3s0fMbNjMdk24rd/Mnjazt6vPi9o7TAB1TeVl/C8l3fCF2+6Q9Iy7r5L0TPU9gB6Wht3dn5d06As33yRpW/X1NkmbWzssAK3W7O/sg+6+v/r6gKTBRj9oZlslbW3ycQC0SO036NzdzazhbAt3H5I0JEnRzwFor2ZbbwfNbKkkVZ+HWzckAO3QbNiflHRb9fVtkp5ozXAAtEv6Mt7MtkvaJGnAzPZK+omkeyX9xsy2SHpf0s3tHGQnXH311WE96rtmffLsvt99992wns29jmRzxrN14bO59Fk/OuvD13HFFVeE9ZGRkYa1RYvibnFW3717d1jvRWnY3f2WBqX4qgIAPYXLZYFCEHagEIQdKARhBwpB2IFCMMW1smbNmrA+ONjwimDt27cvPLbOtsZTES1lnS1zPTY21vR9S/lS1XVab9l5y+p1zku2ZfO6devC+vbt28N6N/DMDhSCsAOFIOxAIQg7UAjCDhSCsAOFIOxAIeizV5YtWxbWo2mm2XLNWU83q2ei47MpqhdffHFYz/rw2ZLMdfrs2fTcbGwLFy5s+r6z85ZNr+1FPLMDhSDsQCEIO1AIwg4UgrADhSDsQCEIO1AI+uyV1atXh/VsW+ZI1sv+6KOPwnq23HO0tXHWw8/uO+ujZ6L57tl9Z/PVs+2ko2sjZs+eHR6bXR+QHd+LeGYHCkHYgUIQdqAQhB0oBGEHCkHYgUIQdqAQ9NkrS5YsCevZOuKRrJ9cdz78mTNnGtayfnHWq87q2brx0fHZfWdjnzVrVljv6+trWMvms2d/3wsWLAjrvSh9ZjezR8xs2Mx2TbjtbjPbZ2avVB83tneYAOqaysv4X0q6YZLb73f3ddXHU60dFoBWS8Pu7s9LOtSBsQBoozpv0P3AzF6rXuYvavRDZrbVzHaa2c4ajwWgpmbD/gtJX5e0TtJ+ST9t9IPuPuTu6919fZOPBaAFmgq7ux9097Pufk7SQ5Kube2wALRaU2E3s6UTvv2OpF2NfhZAb0j77Ga2XdImSQNmtlfSTyRtMrN1klzSe5K+174hdkbWd436yVGfW8rnZWd9+GwN86hPH811l6TR0dGwns13nzNnTljP+vB1ZOft9OnTDWvZOc3+ztr552qXNOzufsskNz/chrEAaCMulwUKQdiBQhB2oBCEHSgEYQcKwRTXyty5c5s+NpuCmrVpohaRVG+aavbYWfsqOz5rO0Zjy6b2ZrKxRe21gYGB8Ng6f65eNf1GDKAphB0oBGEHCkHYgUIQdqAQhB0oBGEHCkGfvZJNBY36rtn2vXW3Js7uPzs+0t/fH9bHxsbCetZvjs5rdn1BJuvTR3327Jxl1zbUvUagG3hmBwpB2IFCEHagEIQdKARhBwpB2IFCEHagENOvWdgmWV816svW3Rb58OHDYT3bmjh6/Pnz54fHDg8Ph/WsH53N5Y/WCTh+/Hh4bDanPNtWObq+IbvvzHRcSppndqAQhB0oBGEHCkHYgUIQdqAQhB0oBGEHCkGfvZL1wqOebTYXPpu3nc2NzrZFPnHiRNOPnfXws154do1B1AvPevjZec2Oj3rp2bgzdY/vhvSZ3cyWm9kOM9ttZm+Y2Q+r2/vN7Gkze7v6vKj9wwXQrKm8jD8j6cfuvlbSX0n6vpmtlXSHpGfcfZWkZ6rvAfSoNOzuvt/dX66+HpX0pqRLJd0kaVv1Y9skbW7TGAG0wFf6nd3MVkr6hqQ/SRp09/1V6YCkwQbHbJW0tcYYAbTAlN+NN7N5kn4r6UfufmRizcdnBUw6M8Ddh9x9vbuvrzVSALVMKexmdpHGg/4rd/9ddfNBM1ta1ZdKiqdPAeiq9GW8jfcYHpb0prv/bELpSUm3Sbq3+vxEW0bYIVkrJWrjZO2rbCnp7LGj1pokjYyMNKxdfvnlte47mwpaZ8nlo0ePhsdGS0FPRdR2rNs6m45TXKfyO/tfS/p7Sa+b2SvVbXdqPOS/MbMtkt6XdHNbRgigJdKwu/sfJTX6b/C61g4HQLtwuSxQCMIOFIKwA4Ug7EAhCDtQCKa4VupMt8z66HX7xdnYoum5M2fODI/Net3Zcs0DAwNhPXr8bGpvdl4zdbayzqbXnpdTXAGcHwg7UAjCDhSCsAOFIOxAIQg7UAjCDhSCPnvlyJEjYb2/v79hLZsTnvV7s7nRWT866rNnS0FnWzpnY8+uIVi8eHHD2ieffBIem/Wys/MWjb3udtH02QH0LMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Wgz17J5i9H87YXLlwYHpv1yfv6+sJ61k+O1q0/efJkrfvO6lk/OupnZ+el7tijufTZPPy6f+5exDM7UAjCDhSCsAOFIOxAIQg7UAjCDhSCsAOFmMr+7MslPSppUJJLGnL3n5vZ3ZL+UdLH1Y/e6e5PtWug7fbQQw+F9Y0bNzasffzxxw1rkrRixYqwvmHDhrCezRmP5lZn68Jnve5s3fms3xztHV93bfY6684/9thj4bHR3u6S9MILL4T1XjSVi2rOSPqxu79sZvMlvWRmT1e1+939X9s3PACtMpX92fdL2l99PWpmb0q6tN0DA9BaX+l3djNbKekbkv5U3fQDM3vNzB4xs0UNjtlqZjvNbGe9oQKoY8phN7N5kn4r6UfufkTSLyR9XdI6jT/z/3Sy49x9yN3Xu/v6+sMF0Kwphd3MLtJ40H/l7r+TJHc/6O5n3f2cpIckXdu+YQKoKw27jb8l+rCkN939ZxNuXzrhx74jaVfrhwegVSybymdmGyX9t6TXJX3ay7hT0i0afwnvkt6T9L3qzbzovuIHO08tWjTp2xmfOXToUFh/9dVXw3rUHqu75HG23HM2VTRSd6nozJVXXtmwFi2/Pd25+6Qndirvxv9R0mQHT9ueOlCi8/e/NwCfQ9iBQhB2oBCEHSgEYQcKQdiBQrCUdCXr+UZ92Wxb46xX/eijj4b1VatWhfVoOma0zLSU/7mz5ZzHxsaaPj7ro2fbKmdbZe/YsSOs15H16aPptd3CMztQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4VI57O39MHMPpb0/oSbBiT9uWMD+Gp6dWy9Oi6JsTWrlWO73N0vnqzQ0bB/6cHNdvbq2nS9OrZeHZfE2JrVqbHxMh4oBGEHCtHtsA91+fEjvTq2Xh2XxNia1ZGxdfV3dgCd0+1ndgAdQtiBQnQl7GZ2g5n9r5ntMbM7ujGGRszsPTN73cxe6fb+dNUeesNmtmvCbf1m9rSZvV19jhel7+zY7jazfdW5e8XMbuzS2Jab2Q4z221mb5jZD6vbu3rugnF15Lx1/Hd2M5sh6S1Jfydpr6QXJd3i7rs7OpAGzOw9SevdvesXYJjZ30gak/Sou19d3fYvkg65+73Vf5SL3P2femRsd0sa6/Y23tVuRUsnbjMuabOkf1AXz10wrpvVgfPWjWf2ayXtcfd33P2UpF9LuqkL4+h57v68pC9uF3OTpG3V19s0/o+l4xqMrSe4+353f7n6elTSp9uMd/XcBePqiG6E/VJJH074fq96a793l/R7M3vJzLZ2ezCTGJywzdYBSYPdHMwk0m28O+kL24z3zLlrZvvzuniD7ss2uvtfSvq2pO9XL1d7ko//DtZLvdMpbePdKZNsM/6Zbp67Zrc/r6sbYd8nafmE7y+rbusJ7r6v+jws6XH13lbUBz/dQbf6PNzl8Xyml7bxnmybcfXAuevm9ufdCPuLklaZ2dfMbKak70p6sgvj+BIz66veOJGZ9Un6pnpvK+onJd1WfX2bpCe6OJbP6ZVtvBttM64un7uub3/u7h3/kHSjxt+R/z9Jd3VjDA3GdYWkV6uPN7o9NknbNf6y7rTG39vYImmxpGckvS3pD5L6e2hsj2l8a+/XNB6spV0a20aNv0R/TdIr1ceN3T53wbg6ct64XBYoBG/QAYUg7EAhCDtQCMIOFIKwA4Ug7EAhCDtQiP8HMxc9BBSw5o4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 123\n",
    "sample_data, sample_label = test_dataset[sample_idx]\n",
    "plt.imshow(sample_data[0].asnumpy(), cmap='gray')  # 0 for first and only channel (since greyscale).\n",
    "print('The image label encoding is ', sample_label)\n",
    "print('the sample label human readable is ', class_names[sample_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a035d4f-2416-4687-b183-85610ef4c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sample label is  Coat\n",
      "<class 'mxnet.ndarray.ndarray.NDArray'>\n",
      "(1, 28, 28)\n",
      "\n",
      "[0.827451]\n",
      "<NDArray 1 @cpu(0)>\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "#print(sample_data)\n",
    "print('the sample label is ', class_names[sample_label])\n",
    "print(type(sample_data))\n",
    "print(sample_data.shape)\n",
    "print(sample_data[0,13,12])\n",
    "print(type(sample_data[0,1,1].asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913124c-0224-444f-9ce2-dad808da7266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66b1db-5b08-4669-9023-d078138148e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d41f0-95c8-414f-92f6-9378fc942169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dddc8215-a809-4f72-b063-450f2b0fb3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.ndarray.ndarray.NDArray'>\n",
      "(1024, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Note the lazy transformation in the transform_first api call\n",
    "test_dataloader = mx.gluon.data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "for data, label in test_dataloader:\n",
    "    break\n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32a648b7-172c-47df-84c8-cb4a79cb9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "453ae1e9-ffdf-4832-b9d6-5cf72d159eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(train=True, root=M4_IMAGES).transform_first(transform)\n",
    "test_dataset = FashionMNIST(train=False, root=M4_IMAGES).transform_first(transform)\n",
    "train_dataloader = mx.gluon.data.DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
    "test_dataloader = mx.gluon.data.DataLoader(train_dataset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ef82e-f342-4613-a1fb-c97b81802285",
   "metadata": {},
   "source": [
    "# 2) Metrics\n",
    "In this section, you'll implement a function to test the prediction quality of networks. Using Accuracy as the evaluation metric, complete the following function that takes a network and a dataloader (with test data) and returns an MXNet Metric that has been updated with labels and predictions. We'll use this function in the next section, when we train classification networks.\n",
    "\n",
    "**Hint**: You'll find classes in the mxnet.metric subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34e2f34a-5675-4f84-b308-9690e6dcb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(network, dataloader):\n",
    "    \"\"\"\n",
    "    Calculates accuracy of the network on the data given by the dataloader.\n",
    "    \n",
    "    :param network: network to be tested\n",
    "    :type network: mx.gluon.Block\n",
    "    :param dataloader: dataloader for test data\n",
    "    :type dataloader: mx.gluon.data.DataLoader\n",
    "    \n",
    "    :return: updated metric\n",
    "    :rtype: mx.metric.EvalMetric\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    accuracy = mx.metric.Accuracy()\n",
    "    # tdqm is a progress bar library?\n",
    "    for data, labels in tqdm(dataloader):\n",
    "        preds = network(data)\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        # print(\"labels is {}     preds are {}\" . format(labels, preds))\n",
    "        accuracy.update(labels,preds)\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8423308e-1e3b-4e2e-94c3-5f6c549062d1",
   "metadata": {},
   "source": [
    "## explanation of mx.gluon.nn.Dense() api\n",
    "Docs are [here](https://mxnet.apache.org/versions/1.6/api/python/docs/api/gluon/nn/index.html#mxnet.gluon.nn.Dense)\n",
    "\n",
    "This is a simple  single layer DNN of 28x28=768 pixel values and 10 outputs corresponding to the different image label classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d90a042e-1651-438d-bd01-5c1970397b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:04<00:00, 102.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.07595)\n",
      "Dense(784 -> 10, linear)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the DNN\n",
    "test_network = mx.gluon.nn.Dense(units=10)\n",
    "\n",
    "# setup the DNN\n",
    "test_network.initialize()\n",
    "\n",
    "# train and evaludate the DNN?\n",
    "metric = calculate_accuracy(test_network, test_dataloader)\n",
    "print(metric.get())\n",
    "print(test_network)\n",
    "isinstance(metric, mx.metric.EvalMetric)\n",
    "assert metric.name == 'accuracy'\n",
    "assert metric.num_inst == 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc1b6e-3a39-44e3-ae5a-5f63f3c63707",
   "metadata": {},
   "source": [
    "# 3) Network\n",
    "In the section, you'll implement a couple of different image classification networks and train then on the FashionMNIST dataset. A train function is already provided in this assignment, because the focus will be on network construction.\n",
    "\n",
    "* sgd is possibly 'simple gradient descent'  It shows up in the list shown [here](https://mxnet.apache.org/versions/1.6/api/python/docs/api/optimizer/index.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6859a688-8b42-4da7-b66c-02d3e82ee3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, dataloader):\n",
    "    softmax_cross_entropy = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = mx.gluon.Trainer(network.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "    for data, label in tqdm(dataloader):\n",
    "        with mx.autograd.record():\n",
    "            output = network(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05589ee0-993a-4d81-bc2b-1a9b22ef0564",
   "metadata": {},
   "source": [
    "Your first model should be a sequential network, with 3 layers. You first layer should have 16 hidden units, the second should have 8 hidden units and the last layer should the correct number of output units for the classification task at hand. You should add ReLU activations on all hidden layers, but not the output layer. You should define network in the cell below.\n",
    "\n",
    "Hint: You'll find classes in the mxnet.gluon.nn subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b687cbe-ebd8-4a73-98ac-052e181d29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "network = mx.gluon.nn.Sequential()\n",
    "network.add(\n",
    "    mx.gluon.nn.Dense(16, activation = 'relu'), # this is layer 1\n",
    "    mx.gluon.nn.Dense(8, activation = 'relu'), # this is layer 2\n",
    "    mx.gluon.nn.Dense(10) # the output layer, corresponding to the 10 class labels, sneaker, sandal, etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6d3fb9b-9cfa-4655-804f-afa5dda7aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(network, mx.gluon.nn.Sequential)\n",
    "assert len(network) == 3\n",
    "assert isinstance(network[0], mx.gluon.nn.Dense)\n",
    "assert network[0].act.name.endswith('relu')\n",
    "assert network[0].weight.shape[0] == 16\n",
    "assert isinstance(network[1], mx.gluon.nn.Dense)\n",
    "assert network[1].act.name.endswith('relu')\n",
    "assert network[1].weight.shape[0] == 8\n",
    "assert isinstance(network[2], mx.gluon.nn.Dense)\n",
    "assert network[2].act is None\n",
    "assert network[2].weight.shape[0] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4270aab4-dca1-4a70-99a0-bb20f9b5969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dense(None -> 16, Activation(relu))\n",
      "  (1): Dense(None -> 8, Activation(relu))\n",
      "  (2): Dense(None -> 10, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87477b5-f2d4-4406-b55a-85a22013a06b",
   "metadata": {},
   "source": [
    "With your network now defined, you should initialize its parameters using the Xavier method in the cell below.\n",
    "\n",
    "**Hint**: You'll find classes in the mxnet.init subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51504d50-b865-4185-9157-8c79e26d8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this guide\n",
    "# https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/init.html\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "initializer = mx.init.Xavier()\n",
    "network.initialize(initializer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dcf3fe3-b881-491e-aaab-b9193026974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(initializer, mx.initializer.Xavier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa239e-de24-48f2-8f39-8178a7e6547e",
   "metadata": {},
   "source": [
    "We'll now check the network summary and see that the network has 12786 trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e52cd6-af4f-4c29-8af5-3d8a95b51e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (1024, 1, 28, 28)               0\n",
      "        Activation-1                    <Symbol dense1_relu_fwd>               0\n",
      "        Activation-2                                  (1024, 16)               0\n",
      "             Dense-3                                  (1024, 16)           12560\n",
      "        Activation-4                    <Symbol dense2_relu_fwd>               0\n",
      "        Activation-5                                   (1024, 8)               0\n",
      "             Dense-6                                   (1024, 8)             136\n",
      "             Dense-7                                  (1024, 10)              90\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 12786\n",
      "   Trainable params: 12786\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 12786\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "network.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d9d7bf4-de43-41fc-a580-d93130c1842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dense(784 -> 16, Activation(relu))\n",
      "  (1): Dense(16 -> 8, Activation(relu))\n",
      "  (2): Dense(8 -> 10, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Now we see the None for input is filled out with 768 pixel values for first layer\n",
    "# compare with first print of the network\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb538c-8b6a-47bf-8b8f-bf0ff2c67d61",
   "metadata": {},
   "source": [
    "And use the calculate_accuracy function defined in the previous section to evaluate the performance of this architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f4aeb95-84b0-4ec7-b481-9077716bc495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 83.78it/s]\n",
      "100%|██████████| 469/469 [00:04<00:00, 100.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.7757333333333334)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(network, train_dataloader)\n",
    "metric = calculate_accuracy(network, test_dataloader)\n",
    "print(metric.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6820f-bd8b-41e3-ab50-359f2f2f40ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
